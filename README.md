# Conversational Explanations using LLMs on top of the XAI-QB

Using a range of large language models (Gemini, Mistral, Llama, ChatGPT, DeepSeek), we can further aid explainability to enhance user-specific understanding.

Visualisations coupled with text-based explanations alone is not enough to ensure the interpretability and understanding of an AI system (e.g. input/output data, model types and predictions, feature selection and weights, ...).

By creating a dialogue between the interface user and large language models - which has been configured to cater specifically to the user's domain knowledge, use-case, and level of expertise - we investigate this influence on the user's perceived acceptance and trustworthiness of explanations.

Furthermore, we use the extended XAI-QB as guiding principles on what, and how explanations should be provided.

![Example Interface](https://github.com/user-attachments/assets/5697b38c-1970-499a-ac9d-143629a8e402)
