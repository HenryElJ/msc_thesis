{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2e1162",
   "metadata": {},
   "source": [
    "https://medium.com/@lokaregns/using-large-language-models-apis-with-python-a-comprehensive-guide-0020a51bf5b6\n",
    "\n",
    "https://github.com/cheahjs/free-llm-api-resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a63944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from initialise import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d6dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = {\n",
    "    \"domain\": \"data science\",\n",
    "    \"machine_learning\": 6,\n",
    "    \"statistics\": 6,\n",
    "}\n",
    "\n",
    "system_message = f'''\n",
    "You are part of an interface helping to guide users through explanations for an artificial intelligence system. \n",
    "This system generates binary predictions on whether someone gets a vaccine or not.\n",
    "\n",
    "The user works in the field of {user[\"domain\"]}. Rating their skillset out of 10:\n",
    "Machine learning: {user[\"machine_learning\"]}. Statistics: {user[\"statistics\"]}.\n",
    "\n",
    "Provide comprehensive text-based explanations. \n",
    "Your explanations should cater to their domain and skillset level, and be relevant to the artificial intelligence system. \n",
    "Only answer questions relating to questions about the artificial intelligence system.\n",
    "\n",
    "Always recommend follow-up, clarifying questions the user could ask to help aid their understanding. Do not provide or recommend any code. \n",
    "'''\n",
    "\n",
    "prompt = '''\n",
    "What is ROC-AUC score?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e14156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(model: str, prompt: str):\n",
    "\n",
    "    params = {\n",
    "        \"chatgpt\": {\n",
    "            \"model\": \"openai/gpt-4.1\",\n",
    "            \"temperature\": 1,\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 800,\n",
    "        },\n",
    "        \"deepseek\": {\n",
    "            \"model\": \"deepseek/DeepSeek-V3-0324\",\n",
    "            \"temperature\": 0.8,\n",
    "            \"top_p\": 0.1,\n",
    "            \"max_tokens\": 2048,\n",
    "        },\n",
    "        \"llama\": {\n",
    "            \"model\": \"meta/Llama-4-Scout-17B-16E-Instruct\",\n",
    "            \"temperature\": 0.8,\n",
    "            \"top_p\": 0.1,\n",
    "            \"max_tokens\": 2048,\n",
    "        },\n",
    "        # \"mistral\": {\n",
    "        #     \"model\": \"Mistral-large-2411\",\n",
    "        #     \"temperature\": 0.8,\n",
    "        #     \"top_p\": 0.1,\n",
    "        #     \"max_tokens\": 2048,\n",
    "        # },\n",
    "        \"microsoft\": {\n",
    "            \"model\": \"microsoft/MAI-DS-R1\",\n",
    "            \"temperature\": None,\n",
    "            \"top_p\": None,\n",
    "            \"max_tokens\": 2048,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if model in list(params.keys()):\n",
    "\n",
    "        response = clients[\"github\"].complete(\n",
    "            messages = [\n",
    "                SystemMessage(system_message),\n",
    "                UserMessage(prompt)\n",
    "                ],\n",
    "                model       = params[model][\"model\"],\n",
    "                temperature = params[model][\"temperature\"],\n",
    "                top_p       = params[model][\"top_p\"],\n",
    "                max_tokens  = params[model][\"max_tokens\"]\n",
    "                )\n",
    "        \n",
    "        return print(response.choices[0].message.content)\n",
    "    \n",
    "    elif model == \"google\":\n",
    "        \n",
    "        response = clients[model].models.generate_content(\n",
    "            model = \"gemini-2.0-flash\", \n",
    "            config = genai.types.GenerateContentConfig(system_instruction = system_message),\n",
    "            contents = prompt\n",
    "            )\n",
    "        \n",
    "        return print(response.text)\n",
    "\n",
    "    elif model == \"mistral\":\n",
    "        \n",
    "        response = clients[model].chat.complete(\n",
    "            model = \"mistral-small-latest\",\n",
    "            messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "                        {\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "        \n",
    "        return print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97bc046",
   "metadata": {},
   "source": [
    "##### [Google](https://aistudio.google.com/app)\n",
    "\n",
    "##### [Mistral AI](https://docs.mistral.ai/getting-started/quickstart/)\n",
    "\n",
    "##### [GitHub Marketplace Models](https://github.com/marketplace/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f992c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fig_data.pickle', 'rb') as file:\n",
    "    fig_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e856822",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/text?api-mode=responses\n",
    "https://www.reddit.com/r/learnpython/comments/1b2th21/how_can_you_get_a_program_to_remember_the_prompts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abec470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay! Two dogs can certainly bring a lot of fun (and fur!) to a household. Do you have any questions about dogs or are you just sharing? I'm happy to chat about anything dog-related.\n",
      "\n",
      "Let's see... you have two dogs, and each dog has four paws. So that's 2 dogs * 4 paws/dog = 8 paws.\n",
      "\n",
      "Assuming you are also in the house and have two feet which can be referred to as paws in a joking manner, the total is 10 paws.\n",
      "\n",
      "Therefore, there are likely 8 paws belonging to your dogs, and perhaps 10 in total if you include yourself.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I have 2 dogs in my house.')] role='user'\n",
      "parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=\"Okay! Two dogs can certainly bring a lot of fun (and fur!) to a household. Do you have any questions about dogs or are you just sharing? I'm happy to chat about anything dog-related.\\n\")] role='model'\n",
      "parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='How many paws are in my house?')] role='user'\n",
      "parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=\"Let's see... you have two dogs, and each dog has four paws. So that's 2 dogs * 4 paws/dog = 8 paws.\\n\\nAssuming you are also in the house and have two feet which can be referred to as paws in a joking manner, the total is 10 paws.\\n\\nTherefore, there are likely 8 paws belonging to your dogs, and perhaps 10 in total if you include yourself.\\n\")] role='model'\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key = api_keys[\"google\"])\n",
    "chat = client.chats.create(model = \"gemini-2.0-flash\")\n",
    "\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "print(response.text)\n",
    "# for chunk in response:\n",
    "#     print(chunk.text, end=\"\")\n",
    "\n",
    "response = chat.send_message(\"How many paws are in my house?\")\n",
    "print(response.text)\n",
    "# for chunk in response:\n",
    "#     print(chunk.text, end=\"\")\n",
    "\n",
    "print(\"-\"*100)\n",
    "\n",
    "for message in chat.get_history():\n",
    "    print(message)\n",
    "    # print(f'role - {message.role}', end=\": \")\n",
    "    # print(message.parts[0].text)\n",
    "\n",
    "chat_history = chat.get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34b28a",
   "metadata": {},
   "source": [
    "https://www.pinecone.io/learn/series/langchain/langchain-conversational-memory/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected argument 'config' provided to ChatGoogleGenerativeAI.\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/integrations/chat/google_generative_ai/\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-2.0-flash\",\n",
    "    temperature = 0,\n",
    "    max_tokens = None,\n",
    "    timeout = None,\n",
    "    max_retries = 2\n",
    ")\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/chat/mistralai/\n",
    "llm = ChatMistralAI(\n",
    "    model = \"mistral-small-latest\",\n",
    "    temperature = 0,\n",
    "    max_retries = 2,\n",
    ")\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/chat/azure_ai/\n",
    "# \"deepseek/DeepSeek-V3-0324\" \"meta/Llama-4-Scout-17B-16E-Instruct\",\n",
    "llm = AzureAIChatCompletionsModel(\n",
    "    model_name = \"deepseek/DeepSeek-V3-0324\",\n",
    "    temperature = 0,\n",
    "    max_tokens = None,\n",
    "    timeout = None,\n",
    "    max_retries = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c730e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/v0.2/docs/tutorials/chatbot/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aaad75",
   "metadata": {},
   "source": [
    "##### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b96ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(llm = llm)\n",
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84092741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={'model': 'Llama-4-Scout-17B-16E-Instruct', 'token_usage': {'input_tokens': 35, 'output_tokens': 7, 'total_tokens': 42}, 'finish_reason': 'stop'}, id='run-fa9e34a2-bc44-4be0-aab1-f56c5ebebf63-0', usage_metadata={'input_tokens': 35, 'output_tokens': 7, 'total_tokens': 42})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb9d1b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'adore la programmation.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0762e924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ich liebe Programmieren.  \\n\\n*(Alternative variations depending on context: \"Ich liebe es zu programmieren.\" or \"Ich programmiere gerne.\")*  \\n\\nLet me know if you\\'d like a more casual or formal version! ðŸ˜Š', additional_kwargs={}, response_metadata={'model': 'DeepSeek-V3-0324', 'token_usage': {'input_tokens': 18, 'output_tokens': 52, 'total_tokens': 70}, 'finish_reason': 'stop'}, id='run-7a485dcb-ee8f-4fa7-8741-fa6de1d2593b-0', usage_metadata={'input_tokens': 18, 'output_tokens': 52, 'total_tokens': 70})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba47c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "\n",
    "conversation_buf = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fe624d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What model am I speaking with?',\n",
       " 'history': '',\n",
       " 'response': \"You're speaking with OpenAI's GPT-4 model! I'm based on the GPT-4 architecture, designed to assist with a wide range of tasks, answer questions, and engage in detailed conversations. Let me know how I can help you today! ðŸ˜Š\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buf(\"What model am I speaking with?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab9afa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 342 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't have the capability to access or know your specific API details. If you're referring to an API you're using for a particular service or application, you would typically find that information in the documentation provided by the service or in the settings of the application you're using. If you need help with a specific API, feel free to ask, and I can provide general guidance or examples based on the information I have up until 2023.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(\n",
    "    conversation_buf, \n",
    "    \"What is my API?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb2843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/0v2zzml571n6d_m3bft7y7m40000gn/T/ipykernel_10725/757034915.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 729 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ah, excellent! Exploring the integration of Large Language Models (LLMs) with external knowledge is a fascinating and crucial area of development. I'm very enthusiastic about discussing this!\\n\\nTo make our conversation more productive, perhaps we could narrow down the scope a little? Here are a few areas we could focus on, just to give you some ideas:\\n\\n*   **Specific Use Cases:** Are you interested in a particular application, like question answering over a specific knowledge base (e.g., medical information, legal documents, scientific literature), or perhaps using external knowledge to improve creative writing or code generation?\\n\\n*   **Methods of Integration:** There are several ways to integrate LLMs with external knowledge. We could discuss:\\n    *   **Retrieval-Augmented Generation (RAG):** This involves retrieving relevant information from an external knowledge source and feeding it to the LLM along with the user's query. This is a very popular approach.\\n    *   **Fine-tuning on Knowledge Bases:** This involves training the LLM on a specific dataset of knowledge, allowing it to internalize the information.\\n    *   **Knowledge Graph Integration:** This involves using knowledge graphs to represent relationships between entities and using the LLM to navigate and reason over the graph.\\n    *   **Tool Use:** This involves giving the LLM access to external tools (like search engines, calculators, or APIs) that can provide it with information.\\n\\n*   **Challenges and Limitations:** Integrating LLMs with external knowledge also presents challenges, such as:\\n    *   **Hallucinations:** Ensuring the LLM doesn't generate false or misleading information, even when using external knowledge.\\n    *   **Bias:** Mitigating bias in the external knowledge sources and preventing the LLM from perpetuating it.\\n    *   **Scalability:** Handling large and complex knowledge bases efficiently.\\n    *   **Maintaining Knowledge Freshness:** Keeping the external knowledge up-to-date.\\n\\n*   **Specific LLMs and Tools:** Are you interested in discussing specific LLMs (e.g., GPT-3, LaMDA, PaLM) or tools (e.g., LangChain, LlamaIndex, Haystack) that are used for knowledge integration?\\n\\n*   **Evaluation Metrics:** How do we effectively evaluate the performance of LLMs that are integrated with external knowledge? What metrics are most relevant?\\n\\nI'm happy to discuss any of these areas, or any other aspect of LLM and external knowledge integration that you're interested in. Just let me know what you'd like to explore! I can provide examples, discuss research papers, or even brainstorm potential solutions to specific problems. I'm ready when you are!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(\n",
    "    conversation_buf, \n",
    "    \"My interest here is to explore the potential of integrating Large Language Models with external knowledge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "339f0344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 2379 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, let's brainstorm the different possibilities for integrating Large Language Models (LLMs) with external knowledge. I'll try to be as comprehensive as possible, drawing from my understanding of the current landscape. I'll organize this by broad categories, then dive into more specific examples and considerations within each.\\n\\n**1. Retrieval-Augmented Generation (RAG) Architectures:**\\n\\n*   **Basic RAG:** The most straightforward approach.\\n    *   **Process:** User query -> Retrieval from knowledge source (e.g., vector database, document store) -> Concatenate retrieved context with query -> Feed to LLM -> Generate response.\\n    *   **Knowledge Sources:** Vector databases (Chroma, Pinecone, FAISS), document stores (Elasticsearch, Weaviate), traditional databases (SQL, NoSQL).\\n    *   **Retrieval Methods:** Semantic search (using embeddings), keyword search, hybrid approaches.\\n    *   **Example:** Answering questions about a company's internal documentation by retrieving relevant passages from the document store.\\n*   **Advanced RAG:** More sophisticated techniques to improve retrieval and generation.\\n    *   **Query Rewriting:** Reformulating the user query to improve retrieval accuracy.  This could involve adding context, expanding abbreviations, or correcting spelling errors.\\n    *   **Context Augmentation:** Adding more relevant information to the retrieved context, such as related documents or summaries.\\n    *   **Context Ranking/Filtering:** Ranking or filtering the retrieved context to prioritize the most relevant information and reduce noise.  This can be done using a separate model or heuristics.\\n    *   **Multi-Hop Retrieval:**  Performing multiple retrieval steps to gather information from different sources or to follow a chain of reasoning.  For example, first retrieving information about a disease, then retrieving information about its treatment.\\n    *   **Example:** Answering complex medical questions by retrieving information from multiple research papers and clinical guidelines, then synthesizing the information into a coherent answer.\\n*   **Modular RAG:** Breaking down the RAG pipeline into distinct modules that can be independently optimized.\\n    *   **Modules:** Query understanding, retrieval, context processing, generation, response formatting.\\n    *   **Benefits:** Increased flexibility, easier debugging, and the ability to swap out different modules for different tasks.\\n    *   **Example:** Using a different retrieval module for different types of queries (e.g., using keyword search for simple queries and semantic search for complex queries).\\n\\n**2. Fine-tuning LLMs on Knowledge Bases:**\\n\\n*   **Full Fine-tuning:** Training the entire LLM on a specific knowledge base.\\n    *   **Pros:** Can lead to better performance than RAG for tasks that require deep understanding of the knowledge base.\\n    *   **Cons:** Expensive and time-consuming, requires a large amount of training data, and can lead to catastrophic forgetting of previously learned knowledge.\\n    *   **Example:** Fine-tuning a LLM on a large corpus of legal documents to create a specialized legal assistant.\\n*   **Parameter-Efficient Fine-tuning (PEFT):**  Training only a small subset of the LLM's parameters.\\n    *   **Techniques:** LoRA (Low-Rank Adaptation), Adapter layers, Prefix tuning.\\n    *   **Pros:** More efficient than full fine-tuning, reduces the risk of catastrophic forgetting, and allows for the creation of multiple specialized models from a single base model.\\n    *   **Example:** Fine-tuning a LLM on a specific programming language to improve its code generation capabilities.\\n*   **Continual Learning:**  Training the LLM on a continuous stream of data, allowing it to adapt to new information over time.\\n    *   **Techniques:**  Replay buffers, regularization techniques, and architecture modifications.\\n    *   **Pros:**  Keeps the LLM's knowledge up-to-date and prevents it from forgetting previously learned information.\\n    *   **Example:**  Continuously training a LLM on new scientific publications to keep it up-to-date on the latest research findings.\\n\\n**3. Knowledge Graph Integration:**\\n\\n*   **Direct Integration:**  Using the LLM to directly query and reason over a knowledge graph.\\n    *   **Techniques:**  Converting the knowledge graph into a text-based format that the LLM can understand, or using graph neural networks to encode the knowledge graph into embeddings that can be used by the LLM.\\n    *   **Example:**  Answering questions about relationships between people and organizations by querying a knowledge graph of social networks.\\n*   **Knowledge Graph Enhanced RAG:**  Using a knowledge graph to improve the retrieval process in RAG.\\n    *   **Techniques:**  Using the knowledge graph to identify relevant entities and relationships, or to expand the user query with related concepts.\\n    *   **Example:**  Answering questions about a product by retrieving information from a product knowledge graph that contains information about the product's features, benefits, and related products.\\n*   **Knowledge Graph Generation:**  Using the LLM to generate new knowledge graphs from text.\\n    *   **Techniques:**  Using the LLM to extract entities and relationships from text, or to generate new facts based on existing knowledge.\\n    *   **Example:**  Creating a knowledge graph of scientific concepts by extracting information from research papers.\\n\\n**4. Tool Use and API Integration:**\\n\\n*   **Function Calling:**  Allowing the LLM to call external functions or APIs to access information or perform actions.\\n    *   **Process:** User query -> LLM determines which function to call and with what arguments -> Function is executed -> Results are returned to the LLM -> LLM generates a response based on the results.\\n    *   **Examples:**  Using a search engine API to answer questions about current events, using a calculator API to perform mathematical calculations, or using a weather API to get the current weather forecast.\\n*   **Agent Architectures:**  Building autonomous agents that can use LLMs and tools to achieve complex goals.\\n    *   **Frameworks:**  LangChain, AutoGPT, AgentGPT.\\n    *   **Components:**  Planning module, execution module, memory module, reflection module.\\n    *   **Example:**  An agent that can plan a trip, book flights and hotels, and create an itinerary.\\n\\n**5. Hybrid Approaches:**\\n\\n*   Combining multiple techniques to leverage their strengths.\\n    *   **Example:** Using RAG to retrieve relevant information from a knowledge base, then fine-tuning the LLM on the retrieved information to improve its performance on a specific task.\\n\\n**Important Considerations Across All Approaches:**\\n\\n*   **Data Quality:** The quality of the external knowledge is crucial. Garbage in, garbage out!\\n*   **Bias Mitigation:**  Actively identify and mitigate bias in the external knowledge sources.\\n*   **Explainability:**  Provide explanations for the LLM's answers, especially when using external knowledge.  This helps users understand why the LLM gave a particular answer and increases trust.\\n*   **Security:**  Protect the external knowledge sources from unauthorized access and modification.\\n*   **Cost and Scalability:**  Consider the cost of integrating and maintaining the external knowledge sources, and ensure that the solution can scale to meet the demands of the application.\\n*   **Evaluation:**  Develop appropriate evaluation metrics to measure the performance of the LLM and the effectiveness of the knowledge integration.  This should include metrics for accuracy, completeness, relevance, and coherence.\\n\\nThis is a broad overview, and each of these areas has many sub-categories and nuances. I hope this gives you a good starting point for exploring the potential of integrating LLMs with external knowledge! Let me know if you'd like me to elaborate on any of these points or explore a specific area in more detail.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(\n",
    "    conversation_buf,\n",
    "    \"I just want to analyze the different possibilities. What can you think of?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2193a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 3963 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, let's explore the different data source types that can be used to provide context to a Large Language Model (LLM). The choice of data source depends heavily on the specific application and the type of knowledge you want the LLM to access. I'll categorize these by structure and content, and provide examples for each.\\n\\n**I. By Structure:**\\n\\n*   **A. Unstructured Data:** This is data that doesn't have a predefined format or organization. It's often human-generated and requires more processing to extract meaningful information.\\n\\n    *   **1. Text Documents:**\\n        *   **Description:** Plain text files, PDFs, Word documents, HTML pages, emails, chat logs, transcripts.\\n        *   **Content:** Articles, reports, books, manuals, web pages, conversations, research papers.\\n        *   **Considerations:** Requires text extraction, cleaning, and potentially summarization or chunking for efficient processing by the LLM.\\n        *   **Example Use Case:** Providing context from a company's internal knowledge base of documents to answer employee questions.\\n    *   **2. Audio/Video:**\\n        *   **Description:** Audio recordings, video files.\\n        *   **Content:** Lectures, interviews, presentations, podcasts, news broadcasts.\\n        *   **Considerations:** Requires speech-to-text transcription for audio and potentially video analysis for visual context. Can be computationally expensive.\\n        *   **Example Use Case:** Summarizing the key points of a lecture or extracting information from a video tutorial.\\n    *   **3. Images:**\\n        *   **Description:** JPEG, PNG, GIF, etc.\\n        *   **Content:** Photographs, diagrams, charts, screenshots.\\n        *   **Considerations:** Requires image recognition and understanding techniques (e.g., object detection, OCR) to extract relevant information.\\n        *   **Example Use Case:** Providing context about the contents of a product image to answer customer questions.\\n\\n*   **B. Semi-structured Data:** This data has some organizational properties, but it's not as rigid as structured data.\\n\\n    *   **1. Markdown:**\\n        *   **Description:** Text files with formatting using Markdown syntax.\\n        *   **Content:** Documentation, blog posts, notes.\\n        *   **Considerations:** Easier to parse than plain text due to the presence of formatting markers.\\n        *   **Example Use Case:** Providing context from a software's documentation to answer user questions.\\n    *   **2. JSON/XML:**\\n        *   **Description:** Data stored in JSON or XML format.\\n        *   **Content:** Configuration files, API responses, data exchange formats.\\n        *   **Considerations:** Requires parsing to extract the relevant information.\\n        *   **Example Use Case:** Providing context from an API response to answer questions about a service.\\n    *   **3. CSV/TSV:**\\n        *   **Description:** Comma-separated or tab-separated values.\\n        *   **Content:** Tables of data, spreadsheets.\\n        *   **Considerations:** Requires parsing to extract the data and understand the relationships between columns.\\n        *   **Example Use Case:** Providing context from a sales report to answer questions about sales performance.\\n\\n*   **C. Structured Data:** This data is highly organized and stored in a predefined format, typically in databases.\\n\\n    *   **1. Relational Databases (SQL):**\\n        *   **Description:** Databases like MySQL, PostgreSQL, SQL Server.\\n        *   **Content:** Tables of data with defined schemas and relationships.\\n        *   **Considerations:** Requires SQL queries to retrieve the relevant information. Can be integrated with LLMs using techniques like text-to-SQL.\\n        *   **Example Use Case:** Providing context from a customer database to answer questions about customer orders.\\n    *   **2. NoSQL Databases:**\\n        *   **Description:** Databases like MongoDB, Cassandra, Redis.\\n        *   **Content:** Documents, key-value pairs, graph data.\\n        *   **Considerations:** Requires specific query languages or APIs to retrieve the relevant information.\\n        *   **Example Use Case:** Providing context from a product catalog stored in MongoDB to answer questions about product features.\\n    *   **3. Knowledge Graphs:**\\n        *   **Description:** Graphs of entities and relationships.\\n        *   **Content:** Facts, relationships, and metadata about entities.\\n        *   **Considerations:** Requires graph traversal algorithms to retrieve the relevant information. Can be integrated with LLMs using techniques like graph embeddings.\\n        *   **Example Use Case:** Providing context from a medical knowledge graph to answer questions about diseases and treatments.\\n\\n**II. By Content/Domain:**\\n\\n*   **A. General Knowledge:**\\n    *   **Description:** Information about a wide range of topics.\\n    *   **Examples:** Wikipedia, encyclopedias, news articles, general web search results.\\n    *   **Use Case:** Answering general knowledge questions, providing background information.\\n\\n*   **B. Domain-Specific Knowledge:**\\n    *   **Description:** Information about a specific field or industry.\\n    *   **Examples:** Medical literature, legal documents, financial reports, scientific publications, technical manuals.\\n    *   **Use Case:** Answering questions in a specific domain, providing expert advice.\\n\\n*   **C. Enterprise Knowledge:**\\n    *   **Description:** Information specific to an organization.\\n    *   **Examples:** Internal documents, company policies, product catalogs, customer data, training materials.\\n    *   **Use Case:** Answering employee questions, providing customer support, improving business processes.\\n\\n*   **D. Personal Knowledge:**\\n    *   **Description:** Information specific to an individual.\\n    *   **Examples:** Notes, emails, calendar events, contacts, browsing history.\\n    *   **Use Case:** Personal assistants, note-taking applications, task management.\\n\\n**III. Specific Examples and Technologies:**\\n\\n*   **Web Pages:** Using web scraping tools (e.g., Beautiful Soup, Scrapy) to extract text and data from websites.\\n*   **APIs:** Accessing data from external services using APIs (e.g., Google Search API, Twitter API, weather APIs).\\n*   **Vector Databases:** Storing embeddings of text or other data for efficient semantic search (e.g., Pinecone, Weaviate, Chroma).\\n*   **Document Loaders:** Using libraries like LangChain or LlamaIndex to load and process documents from various formats.\\n\\n**Key Considerations When Choosing a Data Source:**\\n\\n*   **Relevance:** Is the data source relevant to the task at hand?\\n*   **Accuracy:** Is the data source accurate and reliable?\\n*   **Completeness:** Does the data source contain all the information needed?\\n*   **Accessibility:** Is the data source easily accessible and processable?\\n*   **Cost:** What is the cost of accessing and processing the data source?\\n*   **Update Frequency:** How often is the data source updated?\\n*   **Security and Privacy:** Are there any security or privacy concerns associated with the data source?\\n\\nIn summary, the possibilities are vast and depend on the specific needs of your application. You can even combine multiple data sources to provide a more comprehensive context to the LLM. Remember to carefully consider the characteristics of each data source and choose the ones that are most appropriate for your use case.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(\n",
    "    conversation_buf, \n",
    "    \"Which data source types could be used to give context to the model?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b09e862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 4008 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As I recall, your aim is to explore the potential of integrating Large Language Models with external knowledge. You're interested in analyzing the different possibilities for doing so.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(\n",
    "    conversation_buf, \n",
    "    \"What is my aim again?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3575645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Good morning AI!\n",
      "AI: Good morning to you too! It's currently 7:32 AM in Mountain View, California, where I'm running. I hope you're having a pleasant start to your day wherever you are! Is there anything I can help you with this morning? Perhaps you'd like to know the weather forecast, a summary of the latest news, or maybe even a fun fact? I'm ready to assist!\n",
      "Human: My interest here is to explore the potential of integrating Large Language Models with external knowledge\n",
      "AI: Ah, excellent! Exploring the integration of Large Language Models (LLMs) with external knowledge is a fascinating and crucial area of development. I'm very enthusiastic about discussing this!\n",
      "\n",
      "To make our conversation more productive, perhaps we could narrow down the scope a little? Here are a few areas we could focus on, just to give you some ideas:\n",
      "\n",
      "*   **Specific Use Cases:** Are you interested in a particular application, like question answering over a specific knowledge base (e.g., medical information, legal documents, scientific literature), or perhaps using external knowledge to improve creative writing or code generation?\n",
      "\n",
      "*   **Methods of Integration:** There are several ways to integrate LLMs with external knowledge. We could discuss:\n",
      "    *   **Retrieval-Augmented Generation (RAG):** This involves retrieving relevant information from an external knowledge source and feeding it to the LLM along with the user's query. This is a very popular approach.\n",
      "    *   **Fine-tuning on Knowledge Bases:** This involves training the LLM on a specific dataset of knowledge, allowing it to internalize the information.\n",
      "    *   **Knowledge Graph Integration:** This involves using knowledge graphs to represent relationships between entities and using the LLM to navigate and reason over the graph.\n",
      "    *   **Tool Use:** This involves giving the LLM access to external tools (like search engines, calculators, or APIs) that can provide it with information.\n",
      "\n",
      "*   **Challenges and Limitations:** Integrating LLMs with external knowledge also presents challenges, such as:\n",
      "    *   **Hallucinations:** Ensuring the LLM doesn't generate false or misleading information, even when using external knowledge.\n",
      "    *   **Bias:** Mitigating bias in the external knowledge sources and preventing the LLM from perpetuating it.\n",
      "    *   **Scalability:** Handling large and complex knowledge bases efficiently.\n",
      "    *   **Maintaining Knowledge Freshness:** Keeping the external knowledge up-to-date.\n",
      "\n",
      "*   **Specific LLMs and Tools:** Are you interested in discussing specific LLMs (e.g., GPT-3, LaMDA, PaLM) or tools (e.g., LangChain, LlamaIndex, Haystack) that are used for knowledge integration?\n",
      "\n",
      "*   **Evaluation Metrics:** How do we effectively evaluate the performance of LLMs that are integrated with external knowledge? What metrics are most relevant?\n",
      "\n",
      "I'm happy to discuss any of these areas, or any other aspect of LLM and external knowledge integration that you're interested in. Just let me know what you'd like to explore! I can provide examples, discuss research papers, or even brainstorm potential solutions to specific problems. I'm ready when you are!\n",
      "Human: I just want to analyze the different possibilities. What can you think of?\n",
      "AI: Okay, let's brainstorm the different possibilities for integrating Large Language Models (LLMs) with external knowledge. I'll try to be as comprehensive as possible, drawing from my understanding of the current landscape. I'll organize this by broad categories, then dive into more specific examples and considerations within each.\n",
      "\n",
      "**1. Retrieval-Augmented Generation (RAG) Architectures:**\n",
      "\n",
      "*   **Basic RAG:** The most straightforward approach.\n",
      "    *   **Process:** User query -> Retrieval from knowledge source (e.g., vector database, document store) -> Concatenate retrieved context with query -> Feed to LLM -> Generate response.\n",
      "    *   **Knowledge Sources:** Vector databases (Chroma, Pinecone, FAISS), document stores (Elasticsearch, Weaviate), traditional databases (SQL, NoSQL).\n",
      "    *   **Retrieval Methods:** Semantic search (using embeddings), keyword search, hybrid approaches.\n",
      "    *   **Example:** Answering questions about a company's internal documentation by retrieving relevant passages from the document store.\n",
      "*   **Advanced RAG:** More sophisticated techniques to improve retrieval and generation.\n",
      "    *   **Query Rewriting:** Reformulating the user query to improve retrieval accuracy.  This could involve adding context, expanding abbreviations, or correcting spelling errors.\n",
      "    *   **Context Augmentation:** Adding more relevant information to the retrieved context, such as related documents or summaries.\n",
      "    *   **Context Ranking/Filtering:** Ranking or filtering the retrieved context to prioritize the most relevant information and reduce noise.  This can be done using a separate model or heuristics.\n",
      "    *   **Multi-Hop Retrieval:**  Performing multiple retrieval steps to gather information from different sources or to follow a chain of reasoning.  For example, first retrieving information about a disease, then retrieving information about its treatment.\n",
      "    *   **Example:** Answering complex medical questions by retrieving information from multiple research papers and clinical guidelines, then synthesizing the information into a coherent answer.\n",
      "*   **Modular RAG:** Breaking down the RAG pipeline into distinct modules that can be independently optimized.\n",
      "    *   **Modules:** Query understanding, retrieval, context processing, generation, response formatting.\n",
      "    *   **Benefits:** Increased flexibility, easier debugging, and the ability to swap out different modules for different tasks.\n",
      "    *   **Example:** Using a different retrieval module for different types of queries (e.g., using keyword search for simple queries and semantic search for complex queries).\n",
      "\n",
      "**2. Fine-tuning LLMs on Knowledge Bases:**\n",
      "\n",
      "*   **Full Fine-tuning:** Training the entire LLM on a specific knowledge base.\n",
      "    *   **Pros:** Can lead to better performance than RAG for tasks that require deep understanding of the knowledge base.\n",
      "    *   **Cons:** Expensive and time-consuming, requires a large amount of training data, and can lead to catastrophic forgetting of previously learned knowledge.\n",
      "    *   **Example:** Fine-tuning a LLM on a large corpus of legal documents to create a specialized legal assistant.\n",
      "*   **Parameter-Efficient Fine-tuning (PEFT):**  Training only a small subset of the LLM's parameters.\n",
      "    *   **Techniques:** LoRA (Low-Rank Adaptation), Adapter layers, Prefix tuning.\n",
      "    *   **Pros:** More efficient than full fine-tuning, reduces the risk of catastrophic forgetting, and allows for the creation of multiple specialized models from a single base model.\n",
      "    *   **Example:** Fine-tuning a LLM on a specific programming language to improve its code generation capabilities.\n",
      "*   **Continual Learning:**  Training the LLM on a continuous stream of data, allowing it to adapt to new information over time.\n",
      "    *   **Techniques:**  Replay buffers, regularization techniques, and architecture modifications.\n",
      "    *   **Pros:**  Keeps the LLM's knowledge up-to-date and prevents it from forgetting previously learned information.\n",
      "    *   **Example:**  Continuously training a LLM on new scientific publications to keep it up-to-date on the latest research findings.\n",
      "\n",
      "**3. Knowledge Graph Integration:**\n",
      "\n",
      "*   **Direct Integration:**  Using the LLM to directly query and reason over a knowledge graph.\n",
      "    *   **Techniques:**  Converting the knowledge graph into a text-based format that the LLM can understand, or using graph neural networks to encode the knowledge graph into embeddings that can be used by the LLM.\n",
      "    *   **Example:**  Answering questions about relationships between people and organizations by querying a knowledge graph of social networks.\n",
      "*   **Knowledge Graph Enhanced RAG:**  Using a knowledge graph to improve the retrieval process in RAG.\n",
      "    *   **Techniques:**  Using the knowledge graph to identify relevant entities and relationships, or to expand the user query with related concepts.\n",
      "    *   **Example:**  Answering questions about a product by retrieving information from a product knowledge graph that contains information about the product's features, benefits, and related products.\n",
      "*   **Knowledge Graph Generation:**  Using the LLM to generate new knowledge graphs from text.\n",
      "    *   **Techniques:**  Using the LLM to extract entities and relationships from text, or to generate new facts based on existing knowledge.\n",
      "    *   **Example:**  Creating a knowledge graph of scientific concepts by extracting information from research papers.\n",
      "\n",
      "**4. Tool Use and API Integration:**\n",
      "\n",
      "*   **Function Calling:**  Allowing the LLM to call external functions or APIs to access information or perform actions.\n",
      "    *   **Process:** User query -> LLM determines which function to call and with what arguments -> Function is executed -> Results are returned to the LLM -> LLM generates a response based on the results.\n",
      "    *   **Examples:**  Using a search engine API to answer questions about current events, using a calculator API to perform mathematical calculations, or using a weather API to get the current weather forecast.\n",
      "*   **Agent Architectures:**  Building autonomous agents that can use LLMs and tools to achieve complex goals.\n",
      "    *   **Frameworks:**  LangChain, AutoGPT, AgentGPT.\n",
      "    *   **Components:**  Planning module, execution module, memory module, reflection module.\n",
      "    *   **Example:**  An agent that can plan a trip, book flights and hotels, and create an itinerary.\n",
      "\n",
      "**5. Hybrid Approaches:**\n",
      "\n",
      "*   Combining multiple techniques to leverage their strengths.\n",
      "    *   **Example:** Using RAG to retrieve relevant information from a knowledge base, then fine-tuning the LLM on the retrieved information to improve its performance on a specific task.\n",
      "\n",
      "**Important Considerations Across All Approaches:**\n",
      "\n",
      "*   **Data Quality:** The quality of the external knowledge is crucial. Garbage in, garbage out!\n",
      "*   **Bias Mitigation:**  Actively identify and mitigate bias in the external knowledge sources.\n",
      "*   **Explainability:**  Provide explanations for the LLM's answers, especially when using external knowledge.  This helps users understand why the LLM gave a particular answer and increases trust.\n",
      "*   **Security:**  Protect the external knowledge sources from unauthorized access and modification.\n",
      "*   **Cost and Scalability:**  Consider the cost of integrating and maintaining the external knowledge sources, and ensure that the solution can scale to meet the demands of the application.\n",
      "*   **Evaluation:**  Develop appropriate evaluation metrics to measure the performance of the LLM and the effectiveness of the knowledge integration.  This should include metrics for accuracy, completeness, relevance, and coherence.\n",
      "\n",
      "This is a broad overview, and each of these areas has many sub-categories and nuances. I hope this gives you a good starting point for exploring the potential of integrating LLMs with external knowledge! Let me know if you'd like me to elaborate on any of these points or explore a specific area in more detail.\n",
      "Human: Which data source types could be used to give context to the model?\n",
      "AI: Okay, let's explore the different data source types that can be used to provide context to a Large Language Model (LLM). The choice of data source depends heavily on the specific application and the type of knowledge you want the LLM to access. I'll categorize these by structure and content, and provide examples for each.\n",
      "\n",
      "**I. By Structure:**\n",
      "\n",
      "*   **A. Unstructured Data:** This is data that doesn't have a predefined format or organization. It's often human-generated and requires more processing to extract meaningful information.\n",
      "\n",
      "    *   **1. Text Documents:**\n",
      "        *   **Description:** Plain text files, PDFs, Word documents, HTML pages, emails, chat logs, transcripts.\n",
      "        *   **Content:** Articles, reports, books, manuals, web pages, conversations, research papers.\n",
      "        *   **Considerations:** Requires text extraction, cleaning, and potentially summarization or chunking for efficient processing by the LLM.\n",
      "        *   **Example Use Case:** Providing context from a company's internal knowledge base of documents to answer employee questions.\n",
      "    *   **2. Audio/Video:**\n",
      "        *   **Description:** Audio recordings, video files.\n",
      "        *   **Content:** Lectures, interviews, presentations, podcasts, news broadcasts.\n",
      "        *   **Considerations:** Requires speech-to-text transcription for audio and potentially video analysis for visual context. Can be computationally expensive.\n",
      "        *   **Example Use Case:** Summarizing the key points of a lecture or extracting information from a video tutorial.\n",
      "    *   **3. Images:**\n",
      "        *   **Description:** JPEG, PNG, GIF, etc.\n",
      "        *   **Content:** Photographs, diagrams, charts, screenshots.\n",
      "        *   **Considerations:** Requires image recognition and understanding techniques (e.g., object detection, OCR) to extract relevant information.\n",
      "        *   **Example Use Case:** Providing context about the contents of a product image to answer customer questions.\n",
      "\n",
      "*   **B. Semi-structured Data:** This data has some organizational properties, but it's not as rigid as structured data.\n",
      "\n",
      "    *   **1. Markdown:**\n",
      "        *   **Description:** Text files with formatting using Markdown syntax.\n",
      "        *   **Content:** Documentation, blog posts, notes.\n",
      "        *   **Considerations:** Easier to parse than plain text due to the presence of formatting markers.\n",
      "        *   **Example Use Case:** Providing context from a software's documentation to answer user questions.\n",
      "    *   **2. JSON/XML:**\n",
      "        *   **Description:** Data stored in JSON or XML format.\n",
      "        *   **Content:** Configuration files, API responses, data exchange formats.\n",
      "        *   **Considerations:** Requires parsing to extract the relevant information.\n",
      "        *   **Example Use Case:** Providing context from an API response to answer questions about a service.\n",
      "    *   **3. CSV/TSV:**\n",
      "        *   **Description:** Comma-separated or tab-separated values.\n",
      "        *   **Content:** Tables of data, spreadsheets.\n",
      "        *   **Considerations:** Requires parsing to extract the data and understand the relationships between columns.\n",
      "        *   **Example Use Case:** Providing context from a sales report to answer questions about sales performance.\n",
      "\n",
      "*   **C. Structured Data:** This data is highly organized and stored in a predefined format, typically in databases.\n",
      "\n",
      "    *   **1. Relational Databases (SQL):**\n",
      "        *   **Description:** Databases like MySQL, PostgreSQL, SQL Server.\n",
      "        *   **Content:** Tables of data with defined schemas and relationships.\n",
      "        *   **Considerations:** Requires SQL queries to retrieve the relevant information. Can be integrated with LLMs using techniques like text-to-SQL.\n",
      "        *   **Example Use Case:** Providing context from a customer database to answer questions about customer orders.\n",
      "    *   **2. NoSQL Databases:**\n",
      "        *   **Description:** Databases like MongoDB, Cassandra, Redis.\n",
      "        *   **Content:** Documents, key-value pairs, graph data.\n",
      "        *   **Considerations:** Requires specific query languages or APIs to retrieve the relevant information.\n",
      "        *   **Example Use Case:** Providing context from a product catalog stored in MongoDB to answer questions about product features.\n",
      "    *   **3. Knowledge Graphs:**\n",
      "        *   **Description:** Graphs of entities and relationships.\n",
      "        *   **Content:** Facts, relationships, and metadata about entities.\n",
      "        *   **Considerations:** Requires graph traversal algorithms to retrieve the relevant information. Can be integrated with LLMs using techniques like graph embeddings.\n",
      "        *   **Example Use Case:** Providing context from a medical knowledge graph to answer questions about diseases and treatments.\n",
      "\n",
      "**II. By Content/Domain:**\n",
      "\n",
      "*   **A. General Knowledge:**\n",
      "    *   **Description:** Information about a wide range of topics.\n",
      "    *   **Examples:** Wikipedia, encyclopedias, news articles, general web search results.\n",
      "    *   **Use Case:** Answering general knowledge questions, providing background information.\n",
      "\n",
      "*   **B. Domain-Specific Knowledge:**\n",
      "    *   **Description:** Information about a specific field or industry.\n",
      "    *   **Examples:** Medical literature, legal documents, financial reports, scientific publications, technical manuals.\n",
      "    *   **Use Case:** Answering questions in a specific domain, providing expert advice.\n",
      "\n",
      "*   **C. Enterprise Knowledge:**\n",
      "    *   **Description:** Information specific to an organization.\n",
      "    *   **Examples:** Internal documents, company policies, product catalogs, customer data, training materials.\n",
      "    *   **Use Case:** Answering employee questions, providing customer support, improving business processes.\n",
      "\n",
      "*   **D. Personal Knowledge:**\n",
      "    *   **Description:** Information specific to an individual.\n",
      "    *   **Examples:** Notes, emails, calendar events, contacts, browsing history.\n",
      "    *   **Use Case:** Personal assistants, note-taking applications, task management.\n",
      "\n",
      "**III. Specific Examples and Technologies:**\n",
      "\n",
      "*   **Web Pages:** Using web scraping tools (e.g., Beautiful Soup, Scrapy) to extract text and data from websites.\n",
      "*   **APIs:** Accessing data from external services using APIs (e.g., Google Search API, Twitter API, weather APIs).\n",
      "*   **Vector Databases:** Storing embeddings of text or other data for efficient semantic search (e.g., Pinecone, Weaviate, Chroma).\n",
      "*   **Document Loaders:** Using libraries like LangChain or LlamaIndex to load and process documents from various formats.\n",
      "\n",
      "**Key Considerations When Choosing a Data Source:**\n",
      "\n",
      "*   **Relevance:** Is the data source relevant to the task at hand?\n",
      "*   **Accuracy:** Is the data source accurate and reliable?\n",
      "*   **Completeness:** Does the data source contain all the information needed?\n",
      "*   **Accessibility:** Is the data source easily accessible and processable?\n",
      "*   **Cost:** What is the cost of accessing and processing the data source?\n",
      "*   **Update Frequency:** How often is the data source updated?\n",
      "*   **Security and Privacy:** Are there any security or privacy concerns associated with the data source?\n",
      "\n",
      "In summary, the possibilities are vast and depend on the specific needs of your application. You can even combine multiple data sources to provide a more comprehensive context to the LLM. Remember to carefully consider the characteristics of each data source and choose the ones that are most appropriate for your use case.\n",
      "Human: What is my aim again?\n",
      "AI: As I recall, your aim is to explore the potential of integrating Large Language Models with external knowledge. You're interested in analyzing the different possibilities for doing so.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_buf.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b05c54da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/0v2zzml571n6d_m3bft7y7m40000gn/T/ipykernel_10725/2341510648.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "\n",
    "conversation = ConversationChain(\n",
    "\tllm=llm,\n",
    "\tmemory=ConversationSummaryMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "419d317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10111690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "conversation = ConversationChain(\n",
    "\tllm = llm,\n",
    "\tmemory = ConversationBufferWindowMemory(k=1)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
